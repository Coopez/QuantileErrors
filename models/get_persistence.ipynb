{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pvlib\n",
    "sys.path.append(os.getcwd())\n",
    "from persistence import PVForecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_persistance(ghi, horizon, freq='10s', location=None):\n",
    "    \"\"\"\n",
    "    get a single persistance forecast\n",
    "    \"\"\"\n",
    "\n",
    "    if location is None:\n",
    "        location = pvlib.location.Location(latitude=59.973218,\n",
    "                                       longitude=11.051604,\n",
    "                                       altitude=130,\n",
    "                                       tz='CET')\n",
    "\n",
    "    persistance = PVForecast(measured_signal=ghi, \n",
    "                             binning=None,\n",
    "                             f_h=horizon,\n",
    "                             s_h = '0s',\n",
    "                             f_i=freq,\n",
    "                             location=location)\n",
    "                             \n",
    "    sp = persistance.smart_persistance()     \n",
    "\n",
    "    return sp\n",
    "\n",
    "def get_clearsky2(location, index, G_0=1360, max_sza=90, kind='clear') -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate clearness.\n",
    "    \n",
    "    :param G_0: float\n",
    "        the extra terrestrial radiation received by the Earth from the Sun\n",
    "    :return: G_clear : pandas.Series\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get solar zenith angle (SZA):\n",
    "    sza = location.get_solarposition(index)['zenith']\n",
    "    \n",
    "    \n",
    "\n",
    "    # Get clearsky\n",
    "    if kind=='clearsky':\n",
    "        G_clear = location.get_clearsky(sza.index)\n",
    "    elif kind == 'clear':\n",
    "        # Calculate cos(SZA):\n",
    "        cos_zenith = pvlib.tools.cosd(sza)\n",
    "    else:\n",
    "        print('select clear or clearsky, default to clear')\n",
    "        # Calculate cos(SZA):\n",
    "        cos_zenith = pvlib.tools.cosd(sza)\n",
    "    \n",
    "    # Calculate clearness:\n",
    "    G_clear = G_0 * np.maximum(cos_zenith, np.cos(np.radians(max_sza)))\n",
    "    \n",
    "    return G_clear\n",
    "\n",
    "\n",
    "def get_clearsky(ghi, horizon, freq='10s', location=None):\n",
    "    \"\"\"\n",
    "    get a single persistance forecast\n",
    "    \"\"\"\n",
    "\n",
    "    if location is None:\n",
    "        location = pvlib.location.Location(latitude=59.973218,\n",
    "                                       longitude=11.051604,\n",
    "                                       altitude=130,\n",
    "                                       tz='CET')\n",
    "\n",
    "    persistance = PVForecast(measured_signal=ghi, \n",
    "                             binning=None,\n",
    "                             f_h=horizon,\n",
    "                             s_h = '0s',\n",
    "                             f_i=freq,\n",
    "                             location=location)\n",
    "                             \n",
    "    GHI_clear = persistance.get_clearness()     \n",
    "\n",
    "    return GHI_clear\n",
    "\n",
    "    \n",
    "    \n",
    "def get_spersistance_df(index, horizon_steps=90, location=None, freq='10s', ghi_data_path=None, ghi_df=None,revnorm=False):\n",
    "    \"\"\"\n",
    "    get datafram of persistance forecasts, where the index indicates the time at which the persistance forecast is issued\n",
    "    With a given frequency\n",
    "    A given amount of steps forward in time\n",
    "    \"\"\"\n",
    "    if ghi_data_path == None:\n",
    "        ghi_data_path = 'Data_GHI/KZPR_IRHoSunP'\n",
    "        \n",
    "    # dates = np.sort(list(set(pd.to_datetime(index).date)))\n",
    "    try:\n",
    "        dates = np.sort(list(set(index.dt.date)))\n",
    "    except:\n",
    "        dates = np.sort(list(set(index.date)))\n",
    "    #columns = [(i*10)+10 for i in range(horizon_steps)]\n",
    "    sp_df = pd.DataFrame()\n",
    "\n",
    "    for day in dates:\n",
    "        print(day)\n",
    "    \n",
    "        day_ind = \"\".join(map(lambda x: x, str(day).split(\"-\")))\n",
    "\n",
    "        if ghi_df is None:    \n",
    "            if (ghi_data_path.split('/')[-1].split('_')[0] == 'processed'):\n",
    "                ghi = (pd.read_pickle(f'{ghi_data_path}/{day_ind}.pkl').tz_localize('CET')+1)*(1367/2)\n",
    "            else:\n",
    "                ghi = pd.read_pickle(f'{ghi_data_path}/{day_ind}/{day_ind}.pkl').set_index('date_time').tz_localize('CET')\n",
    "        else:\n",
    "            ghi = ghi_df[ghi_df.index.date == day]\n",
    "            \n",
    "            if revnorm==True:\n",
    "                ghi = (ghi + 1)*(1367/2)\n",
    "    \n",
    "        if location is None:\n",
    "            location = pvlib.location.Location(latitude=59.973218,\n",
    "                                           longitude=11.051604,\n",
    "                                           altitude=130,\n",
    "                                           tz='CET')\n",
    "        elif location == 'sunpoint_target_11':\n",
    "            location = pvlib.location.Location(latitude=59.6625, longitude=5.9538,\n",
    "                                           altitude=8,\n",
    "                                           tz='CET')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # first horizon\n",
    "        sp = get_s_persistance(ghi=ghi, horizon=freq, freq=freq, location=location)\n",
    "\n",
    "        # rest of horizons\n",
    "        for step in range(2,horizon_steps+1):\n",
    "            if freq == '10s':\n",
    "                h_seconds = step*10\n",
    "                sp_step = get_s_persistance(horizon=f'{h_seconds}s', freq=freq, ghi=ghi, location=location)\n",
    "            elif freq == '1h':\n",
    "                h_seconds = step\n",
    "                sp_step = get_s_persistance(horizon=f'{h_seconds}h', freq=freq, ghi=ghi, location=location)\n",
    "            \n",
    "        \n",
    "            sp = pd.concat([sp,sp_step],axis=1)\n",
    "\n",
    "        # Shift forecast to correspond to issued timestamp\n",
    "        sp.columns = [i*10 for i in range(1,horizon_steps+1)]\n",
    "        for i,col_name in enumerate(sp.columns):\n",
    "            try:\n",
    "                sp.iloc[:-i-1,i] = sp.iloc[i+1:,i]\n",
    "            except:\n",
    "                raise ValueError('Not enough data to shift forecast')\n",
    "        \n",
    "        # concat each day\n",
    "        sp_day = sp.loc[index[index.dt.date == day],:]\n",
    "        sp_df = pd.concat([sp_df, sp_day], axis=0)\n",
    "    return sp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path_ghi = \"C:\\\\Users\\\\nikla\\\\Documents\\\\phd\\\\paper2\\\\code\\\\IFE_dataset_model\\\\irr_df_20210622_20240618.pkl\"\n",
    "# irr_df = pd.read_pickle(file_path_ghi)\n",
    "\n",
    "path = 'C:\\\\Users\\\\nikla\\\\Documents\\\\phd\\\\paper2\\\\code\\\\IFE_dataset_model\\\\trainval_df_preprocessed.pkl'\n",
    "trainval_df = pd.read_pickle(path)\n",
    "ghi = trainval_df['GHI'] # notably this does not include a test set\n",
    "\n",
    "index = pd.read_pickle('C:\\\\Users\\\\nikla\\\\Documents\\\\phd\\\\paper2\\\\code\\\\IFE_dataset_model\\\\trainval_C_index.pkl')\n",
    "\n",
    "index_filtered = index.iloc[::3]\n",
    "ghi_rolling = ghi.rolling(window=3).mean()#[index_filtered]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ghi_rolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-06-09 05:52:10+02:00    40.999981\n",
       "2022-06-09 05:52:20+02:00    40.999981\n",
       "2022-06-09 05:52:30+02:00    40.999981\n",
       "2022-06-09 05:52:40+02:00    40.999981\n",
       "2022-06-09 05:52:50+02:00    40.999981\n",
       "                               ...    \n",
       "2024-02-29 16:05:10+01:00     7.999988\n",
       "2024-02-29 16:05:20+01:00     7.999988\n",
       "2024-02-29 16:05:30+01:00     7.999988\n",
       "2024-02-29 16:05:40+01:00     7.999988\n",
       "2024-02-29 16:05:50+01:00     7.999988\n",
       "Name: GHI, Length: 111388, dtype: float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pers = get_spersistance_df(index_filtered, horizon_steps=30, location=None, freq='30s', ghi_data_path=None, ghi_df=ghi_rolling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers.to_pickle('persistence_30s.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\nikla\\Documents\\phd\\paper2\\code\\models\n",
      "res dir path: c:\\Users\\nikla\\Documents\\phd\\paper2\\code\\res\n",
      "Files in res dir: ['data.py', 'ife_data.py', 'model.py', 'readyDat_time_csi_nights_allseason_nora_cam.npz', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "\n",
    "# List what's inside the res directory\n",
    "import os\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "res = os.path.join(parent, 'res')\n",
    "print(\"res dir path:\", res)\n",
    "print(\"Files in res dir:\", os.listdir(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory (e.g., the directory of the notebook)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Go up to project root\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the 'res' directory to sys.path\n",
    "res_path = os.path.join(parent_dir, 'res')\n",
    "sys.path.append(res_path)\n",
    "from data import data_import\n",
    "sunpoint_target = [59.6625, 5.9538]\n",
    "start_date = \"2016-01-01 00:30:00\"\n",
    "end_date = \"2020-12-31 23:30:00\"    \n",
    "sun_index = pd.date_range(start=start_date, end = end_date, freq = '1h', tz='CET')\n",
    "train,train_target,valid,valid_target,_,test_target = data_import(parent_dir)\n",
    "# sun_ghi_data = \n",
    "\n",
    "sun_ghi = pd.DataFrame(index=sun_index, data=np.concatenate([test_target,valid_target,train_target]), columns=['GHI'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01 00:30:00+01:00', '2016-01-01 01:30:00+01:00',\n",
       "               '2016-01-01 02:30:00+01:00', '2016-01-01 03:30:00+01:00',\n",
       "               '2016-01-01 04:30:00+01:00', '2016-01-01 05:30:00+01:00',\n",
       "               '2016-01-01 06:30:00+01:00', '2016-01-01 07:30:00+01:00',\n",
       "               '2016-01-01 08:30:00+01:00', '2016-01-01 09:30:00+01:00',\n",
       "               ...\n",
       "               '2020-12-31 14:30:00+01:00', '2020-12-31 15:30:00+01:00',\n",
       "               '2020-12-31 16:30:00+01:00', '2020-12-31 17:30:00+01:00',\n",
       "               '2020-12-31 18:30:00+01:00', '2020-12-31 19:30:00+01:00',\n",
       "               '2020-12-31 20:30:00+01:00', '2020-12-31 21:30:00+01:00',\n",
       "               '2020-12-31 22:30:00+01:00', '2020-12-31 23:30:00+01:00'],\n",
       "              dtype='datetime64[ns, CET]', length=43848, freq='h')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_ghi.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough data to shift forecast",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 142\u001b[0m, in \u001b[0;36mget_spersistance_df\u001b[1;34m(index, horizon_steps, location, freq, ghi_data_path, ghi_df, revnorm)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     sp\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,i] \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:,i]\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nikla\\anaconda3\\envs\\qe\\Lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\nikla\\anaconda3\\envs\\qe\\Lib\\site-packages\\pandas\\core\\indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nikla\\anaconda3\\envs\\qe\\Lib\\site-packages\\pandas\\core\\indexing.py:1998\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 1998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1999\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2001\u001b[0m     )\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m   2004\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pers \u001b[38;5;241m=\u001b[39m get_spersistance_df(sun_ghi\u001b[38;5;241m.\u001b[39mindex, horizon_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m36\u001b[39m, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msunpoint_target_11\u001b[39m\u001b[38;5;124m\"\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1h\u001b[39m\u001b[38;5;124m'\u001b[39m, ghi_data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ghi_df\u001b[38;5;241m=\u001b[39msun_ghi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGHI\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[7], line 144\u001b[0m, in \u001b[0;36mget_spersistance_df\u001b[1;34m(index, horizon_steps, location, freq, ghi_data_path, ghi_df, revnorm)\u001b[0m\n\u001b[0;32m    142\u001b[0m         sp\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,i] \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:,i]\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot enough data to shift forecast\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# concat each day\u001b[39;00m\n\u001b[0;32m    147\u001b[0m sp_day \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mloc[index[index\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate \u001b[38;5;241m==\u001b[39m day],:]\n",
      "\u001b[1;31mValueError\u001b[0m: Not enough data to shift forecast"
     ]
    }
   ],
   "source": [
    "pers = get_spersistance_df(sun_ghi.index, horizon_steps=36, location=\"sunpoint_target_11\", freq='1h', ghi_data_path=None, ghi_df=sun_ghi[\"GHI\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
